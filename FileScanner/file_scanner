import pyfiglet
import os
import logging
import concurrent.futures
import argparse
from abc import ABC, abstractmethod

ascii_banner = pyfiglet.figlet_format("FILE SCANNER")
print(ascii_banner)

class Logger:
    def __init__(self, log_file="scanner.log"):
        logging.basicConfig(
            filename=log_file,
            level=logging.INFO,
            format="%(asctime)s - %(levelname)s - %(message)s"
        )
        self.logger = logging.getLogger()
    
    def info(self, message):
        self.logger.info(message)
        print(message)
    
    def error(self, message):
        self.logger.error(message)
        print(f"ERROR: {message}")

#Base Class
class FileProcessor(ABC):
    @abstractmethod
    def process(self, file_path: str):
        #Process given file
        pass

#Main class
class FileScanner:
    def __init__(self, directory: str, processor: FileProcessor, logger: Logger, max_workers=4):
        self.directory = directory
        self.processor = processor
        self.logger = logger
        self.max_workers = max_workers

    def scan(self):
        # Scans directory and processes each file"
        if not os.path.exists(self.directory):
            self.logger.error(f"Directory '{self.directory}' not found.")
            return

        self.logger.info(f"Scanning directory: {self.directory}")
        
        files_to_process = []
        for root, _, files in os.walk(self.directory):
            for file in files:
                file_path = os.path.join(root, file)
                files_to_process.append(file_path)

        # Multi-threading to process files in parallel
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = {executor.submit(self.processor.process, file): file for file in files_to_process}        
            for future in concurrent.futures.as_completed(futures) :
                file = futures[future]   
                try:
                    future.result() # Retrieves any raised exceptions
                    self.logger.info(f"Processed file: {file}")
                except Exception as e:
                    self.logger.error(f"Error processing {file}: {e}")


class TextFileProcessor(FileProcessor):
    def __init__(self, logger: Logger):
        self.logger = logger
        
    def process(self, file_path: str):
        #Processes text files by reading the first line
        if file_path.endswith(".txt"):
            try:
                with open(file_path, "r", encoding="utf-8") as file:
                    first_line = file.readline().strip()
                    self.logger.info(f"Processing {file_path}: {first_line}")
            except Exception as e:
                self.logger.error(f"Failed to read {file_path}: {e}")

import csv
class CSVFileProcessor(FileProcessor):
    def __init__(self, logger: Logger):
        self.logger = logger
        
    def process(self, file_path: str):
        #Processes CSV files by reading the first row
        if file_path.endswith(".csv"):
            try:
                with open(file_path, "r", encoding="utf-8") as file:
                    reader = csv.reader(file)
                    first_row = next(reader, None)
                    self.logger.info(f"Processing {file_path}: {first_row}")
            except Exception as e:
                self.logger.error(f"Failed to read {file_path}: {e}")

import json
class JSONFileProcessor(FileProcessor):
    def __init__(self, logger: Logger):
        self.logger = logger
        
    def process(self, file_path: str):
        # Processes JSON files by listing top-level keys
        if file_path.endswith(".json"):
            try:
                with open(file_path, "r", encoding="utf-8") as file:
                    data = json.load(file)
                    keys = list(data.keys()) if isinstance(data,dict) else "Not a JSON object"
                    self.logger.info(f"Processing {file_path}: Keys - {keys}")
            except Exception as e:
                self.logger.error(f"Failed to parse {file_path}: {e}")

from PIL import Image
class ImageFileProcessor(FileProcessor):
    def __init__(self, logger: Logger):
        self.logger = logger
        
    def process(self, file_path: str):
        # Processes image files by extracting dimensions
        if file_path.lower().endswith(".png", ".jpg", ".jpeg", ".gif"):
            try:
                with Image.open(file_path) as img:
                    self.logger.info(f"Processing {file_path}: Size - {img.size}")
            except Exception as e:
                self.logger.error(f"Failed to process {file_path}: {e}")

import pypdf
class PDFFileProcessor(FileProcessor):
    def __init__(self, logger: Logger):
        self.logger = logger
        
    def process(self, file_path: str):
        # Processes PDF files
        if file_path.endswith(".pdf"):
            try:
                with open(file_path, "rb") as file:
                    reader = pypdf.PdfReader(file)
                    text = "\n".join([page.extract_text() for page in reader.pages if page.extract_text()])
                    self.logger.info(f"Processing {file_path}: {text[:500]}...\n") # Log first 500 char
            except Exception as e:
                self.logger.error(f"Failed to process {file_path}: {e}")



# Allows CLI argument functionality
def parse_args():
    parser = argparse.ArgumentParser(description="Scan a directory and process selected file types")
    parser.add_argument(
        "directory", 
        nargs="?", 
        default=".", 
        help="Directory to scan (default: current directory)"
    )
    parser.add_argument(
        "--types",
        nargs="+",
        choices=["txt", "pdf", "csv", "json", "image"],
        default=["txt", "pdf"],
        help="File types to process (e.g. --types txt pdf)"
    )
    return parser.parse_args()


if __name__ == "__main__":
    args = parse_args()
    logger = Logger()
    
    # Map types to processor classes
    processor_map = {
        "txt": TextFileProcessor,
        "pdf": PDFFileProcessor,
        "csv": CSVFileProcessor,
        "json": JSONFileProcessor,
        "image": ImageFileProcessor,
    }

    for file_type in args.types:
        processor_class = processor_map.get(file_type)
        
        if processor_class:
            logger.info(f"Running processor for .{file_type} files...")
            processor = processor_class(logger)
            scanner = FileScanner(args.directory, processor, logger, max_workers=8)
            scanner.scan()
        else:
            logger.error(f"No processor available for: {file_type}.")

